{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import pandas as pd\n",
    "from DQN import DQN_agent_modular\n",
    "from envs.GraphEnv.impnode import ImpnodeEnv\n",
    "from DQN.finetune_dqn import finetune_dqn\n",
    "from DQN.test_and_compare import test_loop, test_loop2\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import mlflow\n",
    "import  numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T17:28:04.689468500Z",
     "start_time": "2024-05-03T17:28:04.443421400Z"
    }
   },
   "id": "69f6d4f234bcad7d",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Experiment: artifact_location='file:///C:/rituja_git/ma-rituja-pardhi/mlruns/21', creation_time=1714560410552, experiment_id='21', last_update_time=1714560410552, lifecycle_stage='active', name='finetune_baseline_models', tags={}>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('sqlite:///mlflow.db')\n",
    "mlflow.set_experiment('finetune_baseline_models')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T17:28:04.827982Z",
     "start_time": "2024-05-03T17:28:04.684468400Z"
    }
   },
   "id": "b2a302624d9d493c",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed = 412\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.use_deterministic_algorithms(True,warn_only=True)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T17:28:04.955521800Z",
     "start_time": "2024-05-03T17:28:04.826981300Z"
    }
   },
   "id": "41ada95199b91755",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_sns(sum_reward_histories, style=\"classic\", plot_size=(10, 8)):\n",
    "    with plt.style.context(style=style):\n",
    "        fig, ax = plt.subplots(figsize=plot_size)\n",
    "        sns.lineplot({'ImpNode_ANC':sum_reward_histories[0], 'ImpNode_ANC_finetune':sum_reward_histories[1]})\n",
    "        \n",
    "        ax.set_title(\"cumulative sum of rewards\", fontsize=14)\n",
    "        ax.set_xlabel(\"num nodes removed\", fontsize=12)\n",
    "        ax.set_ylabel(\"reward\", fontsize=12)\n",
    "        for i in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "            i.set_fontsize(10)\n",
    "        ax.legend_.remove()\n",
    "        plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T17:28:05.097063400Z",
     "start_time": "2024-05-03T17:28:04.958521700Z"
    }
   },
   "id": "613248603c1e39f0",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test(device, model_path, finetuned_model_path, graph_name):\n",
    "    subdir = 'data/real/Cost'\n",
    "    file_name = '{}_degree.gml'.format(graph_name)\n",
    "    data_path = Path.cwd()/subdir\n",
    "    max_removed_nodes = None\n",
    "    NUM_TEST_EPS = 1 # number of test episodes to run\n",
    "    \n",
    "    \n",
    "    env_test = ImpnodeEnv(anc='dw_nd', num_nodes=(30, 50), data_path=data_path,mode='test',  file_name=file_name, max_removed_nodes=max_removed_nodes)\n",
    "    \n",
    "    dqn_agent_test = DQN_agent_modular.DQNAgent(device=device,\n",
    "                                                alpha=0.001,\n",
    "                                        gnn_depth=4,\n",
    "                                        state_size=2,\n",
    "                                        hidden_size1=32,\n",
    "                                        hidden_size2=64,\n",
    "                                        action_size=1,\n",
    "                                        discount=0.0,\n",
    "                                        eps_max=0.0,\n",
    "                                        eps_min=0.0,\n",
    "                                        eps_step=0.0,\n",
    "                                        memory_capacity=0,\n",
    "                                        lr=0,\n",
    "                                        mode='test')\n",
    "    \n",
    "    dqn_agent_test.load_model('{}/model.pt'.format(model_path))\n",
    "    \n",
    "    actions, reward_history, ep_score_history = test_loop2(env=env_test,\n",
    "                                                            agent=dqn_agent_test,\n",
    "                                                            NUM_TEST_EPS = NUM_TEST_EPS,\n",
    "                                                           step_ratio=0.01)\n",
    "    \n",
    "    dqn_agent_test_finetuned = DQN_agent_modular.DQNAgent(device=device,\n",
    "                                                alpha=0.001,\n",
    "                                        gnn_depth=4,\n",
    "                                        state_size=2,\n",
    "                                        hidden_size1=32,\n",
    "                                        hidden_size2=64,\n",
    "                                        action_size=1,\n",
    "                                        discount=0.0,\n",
    "                                        eps_max=0.0,\n",
    "                                        eps_min=0.0,\n",
    "                                        eps_step=0.0,\n",
    "                                        memory_capacity=0,\n",
    "                                        lr=0,\n",
    "                                        mode='test')\n",
    "    \n",
    "    dqn_agent_test_finetuned.load_model('{}/model.pt'.format(finetuned_model_path))\n",
    "    \n",
    "    f_actions, f_reward_history, f_ep_score_history = test_loop2(env=env_test,\n",
    "                                                            agent=dqn_agent_test_finetuned,\n",
    "                                                            NUM_TEST_EPS = NUM_TEST_EPS,\n",
    "                                                                 step_ratio=0.01)\n",
    "    actions = [int(action.to('cpu')) for action in actions]\n",
    "    df_actions = pd.DataFrame(actions)\n",
    "    df_actions.to_csv('{}/actions.csv'.format(finetuned_model_path))\n",
    "    \n",
    "    f_actions = [int(action.to('cpu')) for action in f_actions]\n",
    "    df_f_actions = pd.DataFrame(f_actions)\n",
    "    df_f_actions.to_csv('{}/finetuned_actions.csv'.format(finetuned_model_path))\n",
    "    \n",
    "    #mlflow.log_metric('actions', actions)\n",
    "    #mlflow.log_metric('finetuned_actions', f_actions)\n",
    "    #cum_sum_reward_his = np.cumsum(reward_history)\n",
    "    #cum_sum_hda_reward_his = np.cumsum(f_reward_history)\n",
    "    \n",
    "    #fig = plot_sns([cum_sum_reward_his, cum_sum_hda_reward_his])\n",
    "    \n",
    "    #mlflow.log_figure(fig,'Cumulative reward.png')\n",
    "    #mlflow.log_param('test_graph',graph_name)\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T17:28:05.222067900Z",
     "start_time": "2024-05-03T17:28:05.102064900Z"
    }
   },
   "id": "3b23226643a234c",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def testing(run_id, model_path, finetuned_model_path, graph_name):\n",
    "    \n",
    "    seed = 412\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.use_deterministic_algorithms(True,warn_only=True)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        test(device, model_path, finetuned_model_path, graph_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T17:28:05.347824800Z",
     "start_time": "2024-05-03T17:28:05.223067500Z"
    }
   },
   "id": "febdfe82ed8081ce",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "run_ids = ['3381e0c8fcce4b84a5120b6a9714b822',\n",
    "           '0fc0785ffc3d49d7a9c6883224300d9b',\n",
    "           #'74ee27e3a2194a29bf33c8009fef0945',\n",
    "           'ea8e10d895024d7c9f3b35a0262784d5',\n",
    "           '5f9bbe6b95d448f5b6447f5a57d07bb8',\n",
    "           #'32300d3e7f494257a4d5324c0041a46d',\n",
    "           '9f97a43eb0d345399d9e7647ee6c93be',\n",
    "           '016ee29739714dc9b24ce5e89388749c',\n",
    "           #'ae7de19f6e0245489966e5a7bdf0f0da'\n",
    "           ]\n",
    "model_paths = ['results/train_baseline_models/barabasi-albert_20240430122831',\n",
    "               'results/train_baseline_models/barabasi-albert_20240430122831',\n",
    "               #'results/train_baseline_models/barabasi-albert_20240430122831',\n",
    "               'results/train_baseline_models/erdos-renyi_20240430184633',\n",
    "               'results/train_baseline_models/erdos-renyi_20240430184633',\n",
    "               #'results/train_baseline_models/erdos-renyi_20240430184633',\n",
    "               'results/train_baseline_models/watts-strogatz_20240430231416',\n",
    "               'results/train_baseline_models/watts-strogatz_20240430231416',\n",
    "               #'results/train_baseline_models/watts-strogatz_20240430231416'\n",
    "               ]\n",
    "finetuned_model_paths = \\\n",
    "    ['results/train_baseline_models/barabasi-albert_20240430122831/t-BA_f-Facebook_20240501221814',\n",
    "     'results/train_baseline_models/barabasi-albert_20240430122831/t-BA_f-Gnutella31_20240501230533',\n",
    "     #'results/train_baseline_models/barabasi-albert_20240430122831/t-BA_f-PG_20240501161733',\n",
    "     'results/train_baseline_models/erdos-renyi_20240430184633/t-ER_f-Facebook_20240501234340',\n",
    "     'results/train_baseline_models/erdos-renyi_20240430184633/t-ER_f-Gnutella31_20240502003032',\n",
    "     #'results/train_baseline_models/erdos-renyi_20240430184633/t-ER_f-PG_20240501184319',\n",
    "     'results/train_baseline_models/watts-strogatz_20240430231416/t-WS_f-Facebook_20240502010733',\n",
    "     'results/train_baseline_models/watts-strogatz_20240430231416/t-WS_f-Gnutella31_20240502015348',\n",
    "     #'results/train_baseline_models/watts-strogatz_20240430231416/t-WS_f-PG_20240501202443'\n",
    "     ]\n",
    "graph_names = ['Facebook','Gnutella31',#'PG',\n",
    "               'Facebook','Gnutella31',#'PG',\n",
    "               'Facebook','Gnutella31',#'PG'\n",
    "                 ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T17:28:05.494856Z",
     "start_time": "2024-05-03T17:28:05.347824800Z"
    }
   },
   "id": "77ca0c34b11f48b8",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "for run_id,model_path,finetuned_model_path,graph_name in zip(run_ids,model_paths,finetuned_model_paths,graph_names):\n",
    "    testing(run_id,model_path,finetuned_model_path,graph_name)\n",
    "    print('Finished')\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T18:54:35.883214100Z",
     "start_time": "2024-05-03T17:28:05.489856500Z"
    }
   },
   "id": "fa2a3d60d404608e",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T18:54:35.905699700Z",
     "start_time": "2024-05-03T18:54:35.877116100Z"
    }
   },
   "id": "d530678f3117a33a",
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
