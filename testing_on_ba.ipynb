{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from DQN import DQN_agent_modular\n",
    "from envs.GraphEnv.impnode import ImpnodeEnv\n",
    "from DQN.train_dqn import train_dqn, fill_memory\n",
    "from DQN.finetune_dqn import finetune_dqn\n",
    "from DQN.test_and_compare import test_loop, hda\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import mlflow\n",
    "import  numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:55:08.986175200Z",
     "start_time": "2024-04-29T08:55:08.445607800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "import random\n",
    "seed = 412\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.use_deterministic_algorithms(True,warn_only=True)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:55:09.113687200Z",
     "start_time": "2024-04-29T08:55:08.987175100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "RESULTS_BASEPATH_TEST_ws = 'results/finetune_experiments/cuda_0.001_100000_100_0.99_64_50000_500_1.0_0.05_5000_0.0001_4_2_32_64_1_3_(30, 50)_dw_nd_small-world_20240424134422/11000_model.pt'\n",
    "RESULTS_BASEPATH_TEST_ba = 'results/finetune_experiments/cuda_0.001_100000_100_0.99_64_50000_500_1.0_0.05_5000_0.0001_4_2_32_64_1_3_(30, 50)_dw_nd_barabasi-albert_20240424124037/9000_model.pt'\n",
    "RESULTS_BASEPATH_TEST_er = 'results/finetune_experiments/cuda_0.001_100000_100_0.99_64_50000_500_1.0_0.05_5000_0.0001_4_2_32_64_1_3_(30, 50)_dw_nd_erdos-renyi_20240424134434/20000_model.pt'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:55:09.288699Z",
     "start_time": "2024-04-29T08:55:09.165193700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dqn_agent_test = DQN_agent_modular.DQNAgent(device=device,\n",
    "                                    alpha=0.001,\n",
    "                                    gnn_depth=4,\n",
    "                                    state_size=2,\n",
    "                                    hidden_size1=32,\n",
    "                                    hidden_size2=64,\n",
    "                                    action_size=1,\n",
    "                                    discount=0.0,\n",
    "                                    eps_max=0.0,\n",
    "                                    eps_min=0.0,\n",
    "                                    eps_step=0.0,\n",
    "                                    memory_capacity=0,\n",
    "                                    lr=0,\n",
    "                                    mode='test')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:55:09.888488800Z",
     "start_time": "2024-04-29T08:55:09.755960300Z"
    }
   },
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.35268702651515166"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn_agent_test.load_model('{}'.format(RESULTS_BASEPATH_TEST_ba))\n",
    "subdir = 'data/synthetic_small_dataset/BA_val_30_50'\n",
    "data_path = Path.cwd()/subdir\n",
    "\n",
    "NUM_TEST_EPS = 1 # number of test episodes to run\n",
    " \n",
    "env_test_val = ImpnodeEnv(anc='dw_nd', g_type='barabasi-albert', num_nodes=(30, 50), data_path=data_path, mode='test', max_removed_nodes=None)\n",
    "\n",
    "# test the agent\n",
    "actions2, reward_history2, ep_score_history2 = test_loop(env=env_test_val,\n",
    "                                                         agent=dqn_agent_test,\n",
    "                                                         NUM_TEST_EPS = NUM_TEST_EPS)\n",
    "\n",
    "np.mean(ep_score_history2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:57:08.807170500Z",
     "start_time": "2024-04-29T08:57:08.229413100Z"
    }
   },
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Env is terminated. Use reset()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[97], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m env_test_val \u001B[38;5;241m=\u001B[39m ImpnodeEnv(anc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdw_nd\u001B[39m\u001B[38;5;124m'\u001B[39m, g_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msmall-world\u001B[39m\u001B[38;5;124m'\u001B[39m, num_nodes\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m30\u001B[39m, \u001B[38;5;241m50\u001B[39m), data_path\u001B[38;5;241m=\u001B[39mdata_path, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m, max_removed_nodes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# test the agent\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m actions2, reward_history2, ep_score_history2 \u001B[38;5;241m=\u001B[39m \u001B[43mtest_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menv_test_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m                                                         \u001B[49m\u001B[43magent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdqn_agent_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m                                                         \u001B[49m\u001B[43mNUM_TEST_EPS\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mNUM_TEST_EPS\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m np\u001B[38;5;241m.\u001B[39mmean(ep_score_history2)\n",
      "File \u001B[1;32mC:\\rituja_git\\ma-rituja-pardhi\\DQN\\test_and_compare.py:17\u001B[0m, in \u001B[0;36mtest_loop\u001B[1;34m(env, agent, NUM_TEST_EPS)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m action \u001B[38;5;129;01min\u001B[39;00m action_list:\n\u001B[0;32m     16\u001B[0m     actions\u001B[38;5;241m.\u001B[39mappend(action)\n\u001B[1;32m---> 17\u001B[0m     next_state, reward, done, truncated, _ \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m     ep_score \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m reward\n\u001B[0;32m     19\u001B[0m     state \u001B[38;5;241m=\u001B[39m next_state\n",
      "File \u001B[1;32mC:\\rituja_git\\ma-rituja-pardhi\\envs\\GraphEnv\\impnode.py:106\u001B[0m, in \u001B[0;36mImpnodeEnv.step\u001B[1;34m(self, actions)\u001B[0m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, actions: ActType) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[DiGraph, \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m Any, \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mdict\u001B[39m]:\n\u001B[1;32m--> 106\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_terminated(), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnv is terminated. Use reset()\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;66;03m# if self.mode == 'test':\u001B[39;00m\n\u001B[0;32m    108\u001B[0m     \u001B[38;5;66;03m#     for action in actions:\u001B[39;00m\n\u001B[0;32m    109\u001B[0m     \u001B[38;5;66;03m#         node = action\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;66;03m#         [self.graph.remove_edge(*i) for i in self.graph.edges if int(i[0]) == int(node) or int(i[1]) == int(node)]\u001B[39;00m\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;66;03m# else:\u001B[39;00m\n\u001B[0;32m    116\u001B[0m     node \u001B[38;5;241m=\u001B[39m actions\n",
      "\u001B[1;31mAssertionError\u001B[0m: Env is terminated. Use reset()"
     ]
    }
   ],
   "source": [
    "dqn_agent_test.load_model('{}'.format(RESULTS_BASEPATH_TEST_ws))\n",
    "subdir = 'data/synthetic_small_dataset/WS_val_30_50'\n",
    "data_path = Path.cwd()/subdir\n",
    "\n",
    "NUM_TEST_EPS = 100 # number of test episodes to run\n",
    "\n",
    "env_test_val = ImpnodeEnv(anc='dw_nd', g_type='small-world', num_nodes=(30, 50), data_path=data_path, mode='test', max_removed_nodes=None)\n",
    "\n",
    "# test the agent\n",
    "actions2, reward_history2, ep_score_history2 = test_loop(env=env_test_val,\n",
    "                                                         agent=dqn_agent_test,\n",
    "                                                         NUM_TEST_EPS = NUM_TEST_EPS)\n",
    "\n",
    "np.mean(ep_score_history2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:56:41.668308100Z",
     "start_time": "2024-04-29T08:56:40.765236700Z"
    }
   },
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.19526946140795748"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn_agent_test.load_model('{}'.format(RESULTS_BASEPATH_TEST_er))\n",
    "subdir = 'data/synthetic_small_dataset/ER_val_30_50'\n",
    "data_path = Path.cwd()/subdir\n",
    "\n",
    "NUM_TEST_EPS = 100 # number of test episodes to run\n",
    "\n",
    "env_test_val = ImpnodeEnv(anc='dw_nd', g_type='erdos-renyi', num_nodes=(30, 50), data_path=data_path, mode='test', max_removed_nodes=None)\n",
    "\n",
    "# test the agent\n",
    "actions2, reward_history2, ep_score_history2 = test_loop(env=env_test_val,\n",
    "                                                         agent=dqn_agent_test,\n",
    "                                                         NUM_TEST_EPS = NUM_TEST_EPS)\n",
    "\n",
    "np.mean(ep_score_history2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:40:26.794789200Z",
     "start_time": "2024-04-29T08:40:07.568400Z"
    }
   },
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:40:26.820363600Z",
     "start_time": "2024-04-29T08:40:26.795789500Z"
    }
   },
   "execution_count": 89
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
